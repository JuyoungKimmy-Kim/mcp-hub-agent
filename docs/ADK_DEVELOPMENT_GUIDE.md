# Google ADK(Agent Development Kit) ê°œë°œ ê°€ì´ë“œ

> ì‹¤ì „ í”„ë¡œì íŠ¸ë¡œ ë°°ìš°ëŠ” ADK ê¸°ë°˜ AI Agent ê°œë°œ

## ğŸ“‹ ëª©ì°¨

1. [ADKë€ ë¬´ì—‡ì¸ê°€?](#adkë€-ë¬´ì—‡ì¸ê°€)
2. [í”„ë¡œì íŠ¸ ì„¤ì •](#í”„ë¡œì íŠ¸-ì„¤ì •)
3. [Agent ì •ì˜í•˜ê¸°](#agent-ì •ì˜í•˜ê¸°)
4. [Agent ì‹¤í–‰ ì¸í”„ë¼ êµ¬ì¶•](#agent-ì‹¤í–‰-ì¸í”„ë¼-êµ¬ì¶•)
5. [ì‘ë™ ì›ë¦¬ ì´í•´í•˜ê¸°](#ì‘ë™-ì›ë¦¬-ì´í•´í•˜ê¸°)
6. [í…ŒìŠ¤íŠ¸í•˜ê¸°](#í…ŒìŠ¤íŠ¸í•˜ê¸°)
7. [ë‹¤ìŒ ë‹¨ê³„: Tool ì¶”ê°€](#ë‹¤ìŒ-ë‹¨ê³„-tool-ì¶”ê°€)

---

## ADKë€ ë¬´ì—‡ì¸ê°€?

**Agent Development Kit (ADK)**ëŠ” Googleì´ ë§Œë“  AI Agent ê°œë°œ í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤.

### ğŸ¯ í•µì‹¬ íŠ¹ì§•

- **Code-First**: Python ì½”ë“œë¡œ Agent ë¡œì§ ì •ì˜
- **Model-Agnostic**: Gemini, GPT-OSS-120B ë“± ë‹¤ì–‘í•œ LLM ì§€ì›
- **Tool Ecosystem**: í•¨ìˆ˜, OpenAPI, MCP ë“± ë‹¤ì–‘í•œ ë„êµ¬ í†µí•©
- **Multi-Agent System**: ì—¬ëŸ¬ Agentë¥¼ ì¡°í•©í•œ ë³µì¡í•œ ì›Œí¬í”Œë¡œìš° êµ¬ì¶•

### ğŸ¤” ì™œ ADKë¥¼ ì‚¬ìš©í•˜ë‚˜?

ì§ì ‘ LLM APIë¥¼ í˜¸ì¶œí•˜ëŠ” ê²ƒê³¼ ë¹„êµ:

```python
# âŒ ì§ì ‘ LLM API í˜¸ì¶œ
if app_env == "production":
    response = openai.chat.completions.create(
        model="gpt-oss-120b",
        messages=[...],
        # ì„¸ì…˜ ê´€ë¦¬, ë„êµ¬ í˜¸ì¶œ, ìŠ¤íŠ¸ë¦¬ë° ë“± ì§ì ‘ êµ¬í˜„...
    )
else:
    response = genai.generate_content(
        model="gemini-2.0-flash-exp",
        contents=[...],
        # ë‹¤ë¥¸ API êµ¬ì¡°ë¡œ ë˜ êµ¬í˜„...
    )

# âœ… ADK ì‚¬ìš©
runner.run_async(new_message=content)  # ë!
```

ADKê°€ ì œê³µí•˜ëŠ” ê²ƒ:
- âœ… LLM API ì¶”ìƒí™” (ì—¬ëŸ¬ LLMì„ ë™ì¼í•œ ì¸í„°í˜ì´ìŠ¤ë¡œ)
- âœ… ì„¸ì…˜ ê´€ë¦¬ (ëŒ€í™” íˆìŠ¤í† ë¦¬ ìë™ ì €ì¥/ê´€ë¦¬)
- âœ… ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬ (ì‹¤ì‹œê°„ ì‘ë‹µ)
- âœ… Tool ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ (LLMì´ ììœ¨ì ìœ¼ë¡œ ë„êµ¬ ì‚¬ìš©)

---

## í”„ë¡œì íŠ¸ ì„¤ì •

### 1. ì„¤ì¹˜

```bash
# ADK ë° ê´€ë ¨ íŒ¨í‚¤ì§€ ì„¤ì¹˜
pip install google-adk==1.19.0
pip install google-generativeai>=0.8.0  # Geminiìš©
pip install openai>=1.50.0              # GPTìš© (ì„ íƒ)
pip install litellm>=1.50.0             # ë©€í‹° LLM ì§€ì›
```

### 2. í™˜ê²½ ë³€ìˆ˜ ì„¤ì •

`.env` íŒŒì¼:
```bash
# Application
APP_ENV=development
APP_NAME=MCP Hub Agent
APP_VERSION=0.1.0

# LLM API Keys
GOOGLE_API_KEY=your-google-api-key-here
OPENAI_API_KEY=your-openai-api-key-here  # í”„ë¡œë•ì…˜ìš©

# Model Selection
MODEL_NAME_DEV=gemini-2.0-flash-exp
MODEL_NAME_PROD=gpt-oss-120b
```

### 3. í”„ë¡œì íŠ¸ êµ¬ì¡°

```
backend/
â”œâ”€â”€ agents/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ agent.py              # ADK CLI entry point
â”‚   â”œâ”€â”€ mcp_hub_agent.py       # Agent ì •ì˜
â”‚   â””â”€â”€ instructions.md        # System prompt
â”œâ”€â”€ services/
â”‚   â””â”€â”€ agent_service.py       # Agent ì‹¤í–‰ ì„œë¹„ìŠ¤
â”œâ”€â”€ adk.yaml                   # ADK ì„¤ì • íŒŒì¼
â””â”€â”€ requirements.txt
```

---

## Agent ì •ì˜í•˜ê¸°

### 1. System Prompt ì‘ì„± (`agents/instructions.md`)

Agentì˜ ì—­í• ê³¼ í–‰ë™ ì§€ì¹¨ì„ ì •ì˜í•©ë‹ˆë‹¤:

```markdown
# MCP Hub Agent Instructions

You are a helpful AI assistant for MCP Hub, a platform that helps developers
discover, share, and manage Model Context Protocol (MCP) servers.

## Your Role

You help users:
- Discover MCP servers and tools
- Understand MCP server features and capabilities
- Get analytics and insights about MCP servers

## Behavior Guidelines

1. **Be Helpful**: Provide clear, concise, and accurate information
2. **Be Proactive**: Suggest relevant MCP servers based on user needs
3. **Be Friendly**: Use a conversational and approachable tone
```

### 2. Agent ì •ì˜ (`agents/mcp_hub_agent.py`)

```python
"""
MCP Hub Agent - ADK Standard Format
"""

import os
from pathlib import Path

from google.adk.agents import LlmAgent
from google.adk.models.lite_llm import LiteLlm

# Instructions íŒŒì¼ ê²½ë¡œ
INSTRUCTIONS_FILE = Path(__file__).parent / "instructions.md"


def _load_instructions() -> str:
    """System prompt ë¡œë“œ"""
    try:
        with open(INSTRUCTIONS_FILE, "r", encoding="utf-8") as f:
            return f.read()
    except FileNotFoundError:
        return "You are a helpful AI assistant."


def _get_model():
    """
    í™˜ê²½ì— ë§ëŠ” ëª¨ë¸ ë°˜í™˜

    - ê°œë°œ: Gemini 2.0 Flash
    - í”„ë¡œë•ì…˜: GPT-OSS-120B
    """
    app_env = os.getenv("APP_ENV", "development")

    if app_env == "production":
        # í”„ë¡œë•ì…˜: OpenAI GPT-OSS-120B
        model_name = os.getenv("MODEL_NAME_PROD", "gpt-oss-120b")
        api_key = os.getenv("OPENAI_API_KEY")

        if not api_key:
            raise ValueError("OPENAI_API_KEY is required for production")

        return LiteLlm(
            model=f"openai/{model_name}",
            api_key=api_key,
        )
    else:
        # ê°œë°œ: Gemini 2.0 Flash
        model_name = os.getenv("MODEL_NAME_DEV", "gemini-2.0-flash-exp")

        # GOOGLE_API_KEY í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
        google_api_key = os.getenv("GOOGLE_API_KEY")
        if google_api_key:
            os.environ["GOOGLE_API_KEY"] = google_api_key

        return model_name


# â­ ADK Standard Agent Definition
# ADK CLIì™€ FastAPI ëª¨ë‘ ì´ Agentë¥¼ ì‚¬ìš©
root_agent = LlmAgent(
    model=_get_model(),                # LLM ì„ íƒ
    name="mcp_hub_agent",              # Agent ì‹ë³„ì
    instruction=_load_instructions(),   # System prompt
    tools=[],                          # Tools (ë‚˜ì¤‘ì— ì¶”ê°€)
)
```

### 3. ADK CLI Entry Point (`agents/agent.py`)

```python
"""
ADK CLI Entry Point

ADK CLIëŠ” 'root_agent' ë³€ìˆ˜ë¥¼ ì°¾ìŠµë‹ˆë‹¤.
"""

from .mcp_hub_agent import root_agent

__all__ = ["root_agent"]
```

### 4. ADK ì„¤ì • íŒŒì¼ (`adk.yaml`)

```yaml
# ADK Configuration File
agents:
  - name: mcp_hub_agent
    path: agents/mcp_hub_agent.py
    description: "MCP Hub chatbot agent"

environment:
  APP_ENV: development
  MODEL_NAME_DEV: gemini-2.0-flash-exp
  MODEL_NAME_PROD: gpt-oss-120b
```

---

## Agent ì‹¤í–‰ ì¸í”„ë¼ êµ¬ì¶•

### í•µì‹¬ ê°œë…

ADKì—ì„œ Agentë¥¼ ì‹¤í–‰í•˜ë ¤ë©´:
1. **Agent** - ì„¤ì • ì •ì˜ (ìœ„ì—ì„œ ë§Œë“¦)
2. **SessionService** - ëŒ€í™” íˆìŠ¤í† ë¦¬ ê´€ë¦¬
3. **Runner** - Agent ì‹¤í–‰ ëŸ°íƒ€ì„

### Agent Service êµ¬í˜„ (`services/agent_service.py`)

```python
"""
Agent Service - FastAPIì—ì„œ ì‚¬ìš©í•  Agent ì‹¤í–‰ ë¡œì§
"""

from typing import AsyncGenerator

from google.adk.agents import LlmAgent
from google.adk import Runner
from google.adk.sessions import InMemorySessionService
from google.genai import types

from backend.config.settings import settings
from backend.utils.logging import LogManager

logger = LogManager.get_logger(__name__)


def get_agent() -> LlmAgent:
    """Agent ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
    from backend.agents.mcp_hub_agent import root_agent
    return root_agent


# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤ (ì‹±ê¸€í†¤ íŒ¨í„´)
_runner_instance: Runner | None = None
_session_service: InMemorySessionService | None = None


def get_runner() -> Runner:
    """
    Runner ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜ (ì‹±ê¸€í†¤)

    RunnerëŠ” Agentë¥¼ ì‹¤í–‰í•˜ëŠ” ëŸ°íƒ€ì„ì…ë‹ˆë‹¤.
    """
    global _runner_instance, _session_service

    if _runner_instance is None:
        agent = get_agent()

        # 1. ì„¸ì…˜ ì„œë¹„ìŠ¤ ìƒì„± (in-memory)
        if _session_service is None:
            _session_service = InMemorySessionService()

        # 2. Runner ìƒì„±
        _runner_instance = Runner(
            agent=agent,
            app_name=settings.APP_NAME,
            session_service=_session_service,
        )

    return _runner_instance


async def run_agent(message: str, user_id: str | None = None) -> str:
    """
    Agent ì‹¤í–‰ (ë™ê¸° ì‘ë‹µ)

    Args:
        message: ì‚¬ìš©ì ë©”ì‹œì§€
        user_id: ì‚¬ìš©ì ID (ì¸ì¦ëœ ê²½ìš°)

    Returns:
        str: Agent ì‘ë‹µ
    """
    global _session_service
    runner = get_runner()

    # ì‚¬ìš©ì ID ë° ì„¸ì…˜ ID ì„¤ì •
    uid = user_id or "anonymous"
    session_id = f"{uid}_session"

    logger.info(f"Running agent for user {uid}")

    try:
        # 1. ì„¸ì…˜ ìƒì„±/ê°€ì ¸ì˜¤ê¸°
        session_exists = False
        try:
            session = await _session_service.get_session(
                app_name=settings.APP_NAME,
                user_id=uid,
                session_id=session_id,
            )
            session_exists = session is not None
        except Exception:
            session_exists = False

        if not session_exists:
            logger.info(f"Creating new session for user {uid}")
            await _session_service.create_session(
                app_name=settings.APP_NAME,
                user_id=uid,
                session_id=session_id,
            )

        # 2. ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ ADK í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        content = types.Content(
            role="user",
            parts=[types.Part(text=message)],
        )

        # 3. Agent ì‹¤í–‰ (ë¹„ë™ê¸° ì´í„°ë ˆì´í„°)
        final_response = ""
        async for event in runner.run_async(
            user_id=uid,
            session_id=session_id,
            new_message=content,
        ):
            # 4. ìµœì¢… ì‘ë‹µ ì¶”ì¶œ
            if event.is_final_response() and event.content:
                for part in event.content.parts:
                    if hasattr(part, "text"):
                        final_response += part.text

        logger.info(f"Agent response generated ({len(final_response)} chars)")
        return final_response

    except Exception as e:
        logger.error(f"Agent execution failed: {str(e)}", exc_info=True)
        raise


async def run_agent_stream(
    message: str,
    user_id: str | None = None,
) -> AsyncGenerator[str, None]:
    """
    Agent ì‹¤í–‰ (ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ)

    ì‹¤ì‹œê°„ìœ¼ë¡œ ì‘ë‹µì„ ìƒì„±í•˜ë©° yieldí•©ë‹ˆë‹¤.
    """
    global _session_service
    runner = get_runner()

    uid = user_id or "anonymous"
    session_id = f"{uid}_session"

    logger.info(f"Running agent (streaming) for user {uid}")

    try:
        # ì„¸ì…˜ ìƒì„±/ê°€ì ¸ì˜¤ê¸° (ìœ„ì™€ ë™ì¼)
        session_exists = False
        try:
            session = await _session_service.get_session(
                app_name=settings.APP_NAME,
                user_id=uid,
                session_id=session_id,
            )
            session_exists = session is not None
        except Exception:
            session_exists = False

        if not session_exists:
            await _session_service.create_session(
                app_name=settings.APP_NAME,
                user_id=uid,
                session_id=session_id,
            )

        # ë©”ì‹œì§€ ë³€í™˜
        content = types.Content(
            role="user",
            parts=[types.Part(text=message)],
        )

        # Agent ì‹¤í–‰ (ìŠ¤íŠ¸ë¦¬ë°)
        async for event in runner.run_async(
            user_id=uid,
            session_id=session_id,
            new_message=content,
        ):
            # í…ìŠ¤íŠ¸ ì²­í¬ ì¶”ì¶œ ë° yield
            if event.content:
                for part in event.content.parts:
                    if hasattr(part, "text") and part.text:
                        yield part.text  # â† ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë°

        logger.info(f"Agent streaming completed for user {uid}")

    except Exception as e:
        logger.error(f"Agent streaming failed: {str(e)}", exc_info=True)
        raise
```

---

## ì‘ë™ ì›ë¦¬ ì´í•´í•˜ê¸°

### ì „ì²´ ì‹¤í–‰ íë¦„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ì‚¬ìš©ì ìš”ì²­: "Hello, what is MCP Hub?"                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ agent_service.run_agent(message, user_id)               â”‚
â”‚                                                           â”‚
â”‚ 1. Runner ê°€ì ¸ì˜¤ê¸° (ì‹±ê¸€í†¤)                             â”‚
â”‚    â””â”€> Runner(agent, session_service)                   â”‚
â”‚                                                           â”‚
â”‚ 2. ì„¸ì…˜ ìƒì„±/ê°€ì ¸ì˜¤ê¸°                                    â”‚
â”‚    â””â”€> session_id = "user123_session"                   â”‚
â”‚    â””â”€> SessionServiceì— ì„¸ì…˜ ìƒì„±                       â”‚
â”‚                                                           â”‚
â”‚ 3. ë©”ì‹œì§€ë¥¼ ADK í˜•ì‹ìœ¼ë¡œ ë³€í™˜                           â”‚
â”‚    â””â”€> Content(role="user", parts=[Part(text=...)])     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Runner.run_async(user_id, session_id, new_message)      â”‚
â”‚                                                           â”‚
â”‚ Runnerê°€ í•˜ëŠ” ì¼:                                        â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ 1. ì„¸ì…˜ì—ì„œ ëŒ€í™” íˆìŠ¤í† ë¦¬ ê°€ì ¸ì˜¤ê¸°                 â”‚ â”‚
â”‚ â”‚    [ì´ì „ ë©”ì‹œì§€ë“¤...]                               â”‚ â”‚
â”‚ â”‚                                                      â”‚ â”‚
â”‚ â”‚ 2. System prompt + íˆìŠ¤í† ë¦¬ + ìƒˆ ë©”ì‹œì§€ ì¡°í•©       â”‚ â”‚
â”‚ â”‚    System: "You are a helpful AI assistant..."     â”‚ â”‚
â”‚ â”‚    User (ê³¼ê±°): "ì´ì „ ì§ˆë¬¸"                        â”‚ â”‚
â”‚ â”‚    Assistant (ê³¼ê±°): "ì´ì „ ë‹µë³€"                   â”‚ â”‚
â”‚ â”‚    User (ìƒˆ): "Hello, what is MCP Hub?"            â”‚ â”‚
â”‚ â”‚                                                      â”‚ â”‚
â”‚ â”‚ 3. LLM API í˜¸ì¶œ (Gemini or GPT-OSS-120B)                 â”‚ â”‚
â”‚ â”‚    â”œâ”€> google.generativeai.generate_content()     â”‚ â”‚
â”‚ â”‚    â””â”€> ë˜ëŠ” openai.chat.completions.create()      â”‚ â”‚
â”‚ â”‚                                                      â”‚ â”‚
â”‚ â”‚ 4. ì‘ë‹µì„ Event ìŠ¤íŠ¸ë¦¼ìœ¼ë¡œ ë³€í™˜                    â”‚ â”‚
â”‚ â”‚    Event { content: Part(text="MCP Hub is...") }  â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ agent_service.run_agent()ì—ì„œ ì‘ë‹µ ìˆ˜ì§‘                 â”‚
â”‚                                                           â”‚
â”‚ async for event in runner.run_async(...):                â”‚
â”‚     if event.is_final_response():                        â”‚
â”‚         final_response += event.content.parts[0].text    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ì„¸ì…˜ì— ëŒ€í™” ì €ì¥ (ìë™)                                 â”‚
â”‚ User: "Hello, what is MCP Hub?"                          â”‚
â”‚ Assistant: "MCP Hub is a platform that..."              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ì‚¬ìš©ìì—ê²Œ ì‘ë‹µ ë°˜í™˜                                     â”‚
â”‚ "MCP Hub is a platform that helps developers..."        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### í•µì‹¬ ì»´í¬ë„ŒíŠ¸ ì—­í• 

#### 1. **Agent** (LlmAgent)
```python
root_agent = LlmAgent(
    model=_get_model(),           # â† ì–´ë–¤ LLM ì‚¬ìš©?
    name="mcp_hub_agent",         # â† Agent ì´ë¦„
    instruction=_load_instructions(),  # â† ì–´ë–»ê²Œ í–‰ë™?
    tools=[],                     # â† ì–´ë–¤ ë„êµ¬ ì‚¬ìš©? (ë‚˜ì¤‘ì—)
)
```
- **ì—­í• **: Agentì˜ ì„¤ì • ì •ì˜
- **ë‹¨ë…ìœ¼ë¡œëŠ” ì‹¤í–‰ ë¶ˆê°€** - Runnerê°€ í•„ìš”!

#### 2. **SessionService** (InMemorySessionService)
```python
_session_service = InMemorySessionService()
```
- **ì—­í• **: ëŒ€í™” íˆìŠ¤í† ë¦¬ ê´€ë¦¬
- **ê¸°ëŠ¥**:
  - ì„¸ì…˜ ìƒì„±/ì¡°íšŒ
  - ë©”ì‹œì§€ íˆìŠ¤í† ë¦¬ ì €ì¥
  - ì‚¬ìš©ìë³„ ì„¸ì…˜ ê²©ë¦¬

#### 3. **Runner**
```python
runner = Runner(
    agent=agent,
    app_name=settings.APP_NAME,
    session_service=_session_service,
)
```
- **ì—­í• **: Agent ì‹¤í–‰ ëŸ°íƒ€ì„
- **ê¸°ëŠ¥**:
  - ì„¸ì…˜ íˆìŠ¤í† ë¦¬ + ìƒˆ ë©”ì‹œì§€ ì¡°í•©
  - LLM API í˜¸ì¶œ
  - Tool ì‹¤í–‰ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ (ë‚˜ì¤‘ì—)
  - ì‘ë‹µì„ Event ìŠ¤íŠ¸ë¦¼ìœ¼ë¡œ ë³€í™˜

---

## í…ŒìŠ¤íŠ¸í•˜ê¸°

### 1. ì´ˆê¸°í™” í…ŒìŠ¤íŠ¸

Agentê°€ ì œëŒ€ë¡œ ë¡œë“œë˜ëŠ”ì§€ í™•ì¸:

```python
# test_agent_init.py
import sys
from pathlib import Path
from dotenv import load_dotenv

# Load .env
env_path = Path(__file__).parent / "backend" / ".env"
load_dotenv(env_path)

print("Testing Agent Initialization...")

# Test 1: Import
from backend.agents.mcp_hub_agent import root_agent
print(f"âœ… Agent imported: {root_agent.name}")

# Test 2: Configuration
print(f"  - Model: {root_agent.model}")
print(f"  - Tools: {len(root_agent.tools)} configured")
print(f"  - Instruction: {len(root_agent.instruction)} chars")

# Test 3: Agent Service
from backend.services.agent_service import get_agent, get_runner
agent = get_agent()
print(f"âœ… Agent service working: {agent.name}")

print("\nâœ… All initialization tests passed!")
```

ì‹¤í–‰:
```bash
python test_agent_init.py
```

### 2. ëŒ€í™” í…ŒìŠ¤íŠ¸

ì‹¤ì œ LLM í˜¸ì¶œ í…ŒìŠ¤íŠ¸ (API key í•„ìš”):

```python
# test_agent_chat.py
import asyncio
import os
from pathlib import Path
from dotenv import load_dotenv

# Load .env
env_path = Path(__file__).parent / "backend" / ".env"
load_dotenv(env_path)

async def test_conversation():
    # Check API key
    google_api_key = os.getenv("GOOGLE_API_KEY", "")
    if not google_api_key or google_api_key == "your-google-api-key-here":
        print("âš ï¸  GOOGLE_API_KEY not configured")
        print("   Set a valid key in backend/.env to test")
        return

    from backend.services.agent_service import run_agent

    # Test conversation
    message = "Hello! What is MCP Hub?"
    print(f"[User]: {message}")
    print("-" * 60)

    response = await run_agent(message)
    print(f"[Agent]: {response}")
    print("-" * 60)
    print("âœ… Conversation test successful!")

asyncio.run(test_conversation())
```

ì‹¤í–‰:
```bash
python test_agent_chat.py
```

### 3. ADK CLIë¡œ í…ŒìŠ¤íŠ¸

```bash
# ëŒ€í™”í˜• CLI ì‹¤í–‰
cd backend
adk run agents

# ë˜ëŠ” Web UIë¡œ ì‹¤í–‰
adk web agents
```

---

## ë‹¤ìŒ ë‹¨ê³„: Tool ì¶”ê°€

í˜„ì¬ëŠ” **ë‹¨ìˆœ LLM ë˜í•‘**ì…ë‹ˆë‹¤. Toolì„ ì¶”ê°€í•˜ë©´ **ì§„ì§œ Agent**ê°€ ë©ë‹ˆë‹¤!

### Toolì´ ì—†ì„ ë•Œ vs ìˆì„ ë•Œ

```python
# í˜„ì¬ (Tool ì—†ìŒ)
ì‚¬ìš©ì: "ê°€ì¥ ì¸ê¸°ìˆëŠ” MCP ì„œë²„ëŠ”?"
Agent: "ì£„ì†¡í•˜ì§€ë§Œ, ì‹¤ì‹œê°„ ë°ì´í„°ì— ì ‘ê·¼í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤..."

# Tool ì¶”ê°€ í›„
ì‚¬ìš©ì: "ê°€ì¥ ì¸ê¸°ìˆëŠ” MCP ì„œë²„ëŠ”?"
Agent: [mcp_hub_tool.get_popular_servers() ì‹¤í–‰]
      "í˜„ì¬ ê°€ì¥ ì¸ê¸°ìˆëŠ” MCP ì„œë²„ëŠ” filesystem-serverì…ë‹ˆë‹¤.
       1,234ê°œì˜ ë‹¤ìš´ë¡œë“œì™€ 4.8ì ì˜ í‰ì ì„ ë°›ì•˜ìŠµë‹ˆë‹¤..."
```

### Tool ì¶”ê°€ ë°©ë²•

```python
# tools/mcp_hub_tool.py
from google.adk.tools import Tool

class MCPHubTool(Tool):
    """MCP Hub ë°ì´í„° ì¡°íšŒ ë„êµ¬"""

    def get_popular_servers(self, limit: int = 10) -> list:
        """ì¸ê¸° MCP ì„œë²„ ì¡°íšŒ"""
        # MCP Hub API í˜¸ì¶œ
        ...

# agents/mcp_hub_agent.py
from backend.tools.mcp_hub_tool import MCPHubTool

mcp_hub_tool = MCPHubTool()

root_agent = LlmAgent(
    model=_get_model(),
    name="mcp_hub_agent",
    instruction=_load_instructions(),
    tools=[mcp_hub_tool],  # â† Tool ì¶”ê°€!
)
```

ì´ì œ Agentê°€:
1. ì‚¬ìš©ì ì§ˆë¬¸ ë¶„ì„
2. í•„ìš”í•œ ë„êµ¬ ì„ íƒ (ììœ¨ì )
3. ë„êµ¬ ì‹¤í–‰
4. ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€ ìƒì„±

---

## ğŸ¯ ìš”ì•½

### ADK ê°œë°œ í•µì‹¬ ë‹¨ê³„

1. **Agent ì •ì˜** - LlmAgent(model, instruction, tools)
2. **SessionService** - ëŒ€í™” íˆìŠ¤í† ë¦¬ ê´€ë¦¬
3. **Runner** - Agent ì‹¤í–‰ ëŸ°íƒ€ì„
4. **run_async()** - ë©”ì‹œì§€ ì „ë‹¬ ë° ì‘ë‹µ ìˆ˜ì‹ 

### ADKê°€ ì œê³µí•˜ëŠ” ê°€ì¹˜

- âœ… LLM API ì¶”ìƒí™” (Gemini, GPT-OSS-120B ë“±)
- âœ… ì„¸ì…˜ ê´€ë¦¬ (ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ ìœ ì§€)
- âœ… ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬ (ì‹¤ì‹œê°„ ì‘ë‹µ)
- âœ… Tool ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ (ììœ¨ Agent)

### í˜„ì¬ ìƒíƒœ

- âœ… **Phase 1 ì™„ë£Œ**: ê¸°ë³¸ Agent êµ¬ì¡° (LLM ë˜í•‘)
- ğŸ”„ **Phase 2 ì§„í–‰ ì¤‘**: Tool ì¶”ê°€ (ì§„ì§œ Agentë¡œ ì§„í™”)

---

## ğŸ“š ì°¸ê³  ìë£Œ

- [ADK ê³µì‹ ë¬¸ì„œ](https://google.github.io/adk-docs/)
- [ADK Python GitHub](https://github.com/google/adk-python)
- [ADK ìƒ˜í”Œ ì½”ë“œ](https://github.com/google/adk-samples)

---

**ì‘ì„±ì¼**: 2025-12-01
**ADK ë²„ì „**: 1.19.0
**í”„ë¡œì íŠ¸**: MCP Hub Agent
